# PubMedCLIP 
Source code for fine-tuning CLIP using image--text pairs in PubMed articles from ROCO dataset.
<br \>
The fine-tuned PubMedCLIP models with ViT32, RN50 and RN50x4 visual encoders are provided on [GDrive](https://drive.google.com/drive/folders/1nCU_3PxQ-thitS76mmJ3W8RergPsN961?usp=sharing). In case of access permission issues, open an issue on this repository.
<br \>
## How to use
This project requires Python 3.7 or newer.
1. Download ROCO dataset from [the official repository](https://github.com/razorx89/roco-dataset),
2. Create your virtual environment, activate it and install ``` pip install -r requirements.txt ```,
3. Set the input paths in `run.sh`,
4. Run `run.sh`.


